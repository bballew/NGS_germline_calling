#!/usr/bin/env python3
# Authors: Shalabh Suman, Bari Ballew


'''Joint variant calling with GATK HaplotypeCaller and Google DeepVariant.

Notes:
    This pipeline is for use with the production germline pipeline.
    Therefore, some things are assumed, e.g. that input bams are indexed,
    that the reference genome is appropriately indexed, etc.  The pipeline
    will halt if these assumptions are not true, but there are no rules
    to perform these tasks.

Input:
    Customized config.yaml, sorted/indexed bams

Output:
    Merged multi-sample VCFs, one called with HaplotypeCaller, and one
    called with DeepVariant

'''


import os
import subprocess
import glob

# reference the config file
conf = os.environ.get("conf")
configfile: conf

# import variables from the config file
refGenome = config['refGenome']
gatkPath = config['gatkPath'].rstrip('/') + '/'  # ensure one trailing slash
snakePath = config['snakePath'].rstrip('/') + '/'
intervalFile = config['intervalFile']
bedFile = config['bedFile']
outDir = config['outputDir'].rstrip('/') + '/'
inDir = config['inputDir'].rstrip('/') + '/'
tempDir=config['tempDir'].rstrip('/') + '/'
logDir = config['logDir'].rstrip('/') + '/'
modelPath = config['modelPath']
useShards = config['useShards']
if useShards:
    numShards = config['numShards']
    maxShards = "{:05d}".format(numShards)
    s = list(range(numShards))
    shardsList = ["%05d" % n for n in s]

CALLERS = ['HC','DV']

# derive additional refgenome variables
refFile = os.path.basename(refGenome)
refDir = os.path.dirname(refGenome)
refNoExt = os.path.splitext(refFile)[0]
dictionaryFile = refDir + '/' + refNoExt + '.dict'

# set a datetime stamp for GATK DBImport step
dt = str(config['dt'])

# read all *.bam filenames in input directory into list (assume bams are indexed)
# this assumption is enforced in input to DV and HC calling rules; the pipeline
# will terminate with an error without .bai files
bamList = [f for f in os.listdir(inDir) if f.endswith('.bam')]

# generate sampleList based on bam filenames
sampleList = [os.path.splitext(f)[0] for f in bamList]

# read in chromosome list from reference dict file (assumes the dict is already created)
# this circumvents the issue of whether to use hg19-style or b37-style chromosome annotation
# as it just pulls the chromosome names directly from the dict index.
chromList = []
with open(dictionaryFile) as f:
    next(f)
    for line in f:
        f1 = line.split("\t")[1]
        f2 = f1.split(":")[1]
        if not subprocess.call(['grep', '-q', '^' + f2 + ':', intervalFile]): # exclude chroms not in the regions of interest, otherwise creates an empty interval file which GATK doesn't like
            chromList.append(f2)

def get_DBImport_path1(wildcards):
    return(glob.glob(outDir + 'HaplotypeCaller/DBImport/' + dt + '_' + wildcards.chrom + '/' + wildcards.chrom + '*/genomicsdb_meta_dir/genomicsdb_meta*.json'))

def get_DBImport_path2(wildcards):
    path = ''.join(glob.glob(outDir + 'HaplotypeCaller/DBImport/' + dt + '_' + wildcards.chrom + '/*/__*/'))
    myList = []
    if os.path.exists(path):
        myList = ['AD.tdb', 'AD_var.tdb', 'ALT.tdb', 'ALT_var.tdb', 'BaseQRankSum.tdb', '__book_keeping.tdb.gz', '__coords.tdb', 'DP_FORMAT.tdb', 'DP.tdb', 'DS.tdb', 'END.tdb', 'ExcessHet.tdb', 'FILTER.tdb', 'FILTER_var.tdb', 'GQ.tdb', 'GT.tdb', 'GT_var.tdb', 'ID.tdb', 'ID_var.tdb', 'InbreedingCoeff.tdb', 'MIN_DP.tdb', 'MLEAC.tdb', 'MLEAC_var.tdb', 'MLEAF.tdb', 'MLEAF_var.tdb', 'MQRankSum.tdb', 'PGT.tdb', 'PGT_var.tdb', 'PID.tdb', 'PID_var.tdb', 'PL.tdb', 'PL_var.tdb', 'QUAL.tdb', 'RAW_MQandDP.tdb', 'ReadPosRankSum.tdb', 'REF.tdb', 'REF_var.tdb', 'SB.tdb', '__tiledb_fragment.tdb']
        myList = [path + file for file in myList]
    return(myList)

report: 'report/workflow.rst'


rule all:
    input:
        # outDir + 'HaplotypeCaller/genotyped/combined/HC_variants.vcf.gz.tbi',
        expand(outDir + 'deepVariant/called/vcfs/{sample}_all_chroms.vcf.gz', sample=sampleList),
        # outDir + 'deepVariant/genotyped/DV_variants.vcf.gz.tbi',
        outDir + 'ensemble/all_callers_merged_genotypes.vcf.gz.tbi'

        # if we want to allow options for calling without combining/harmonizing, will need conditional inputs here and below at include statements

rule split_bed_file:
    '''Separates bed regions by chromosome.

    For DV:
    If you're not assigning a number of shards by which to divide
    and parallelize, then the pipeline will parallelize by chrom.
    To do this, we take the bed file (e.g. exome capture region)
    and split the regions by chromosome.  Subsequent steps are run
    concurrently on each of the single-chromosome bed files.

    For GATK:
    HaplotypeCaller can't be parallelized per task (e.g. threads),
    so must be run over sub-regions if you want parallelization.
    **Do we want to use the old 4000-region bed file, or is by-chrom
    sufficient?

    Note that grep exits with 0 if a match is found, 1 if no match,
    and 2 if error.  Snakemake looks for exit codes of 0 to determine
    that a job finished successfully.  No match is an acceptable outcome
    here, so the shell command below should allow match or no match.

    don't love the || true solution; what will it do for exit > 1?
    '''
    input:
        bed = bedFile,
        interval = intervalFile
    output:
        bed = outDir + 'split_regions/{chrom}.bed',
        interval = outDir + 'split_regions/{chrom}.intervals'
    benchmark:
        'run_times/split_bed_file/{chrom}.tsv'
    shell:
        'grep "^{wildcards.chrom}[[:space:]]" {input.bed} > {output.bed} || true;'
        'grep "^{wildcards.chrom}:" {input.interval} > {output.interval} || true'
        #'grep -m1 {wildcards.chrom} {input}; if [ $? -lt 2 ]; then grep {wildcards.chrom} {input} > {output}; fi'


include: 'Snakefile_HaplotypeCaller'
include: 'Snakefile_DeepVariant'
include: 'Snakefile_harmonize'




